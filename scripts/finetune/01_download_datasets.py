"""
3ê°œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° ê¸°ì´ˆ íƒìƒ‰ ìŠ¤í¬ë¦½íŠ¸.
- ourafla/Mental-Health_Text-Classification_Dataset (HuggingFace)
- nikhileswarkomati/suicide-watch (Kaggle) â†’ C-SSRSì™€ ë™ì¼ ì¶œì²˜
- DepressionEmo (GitHub)

ì‚¬ìš©ë²•:
  python scripts/finetune/01_download_datasets.py
"""

from pathlib import Path
from datasets import load_dataset
import json
import csv
import subprocess
import urllib.request
import zipfile

DATA_DIR = Path("data/finetune_raw")
DATA_DIR.mkdir(parents=True, exist_ok=True)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. ourafla 4-Class (HuggingFace)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def download_ourafla():
    """Suicidal / Depression / Anxiety / Normal 4ë¶„ë¥˜ ë°ì´í„°ì…‹"""
    out_dir = DATA_DIR / "ourafla"
    if out_dir.exists() and any(out_dir.glob("*.csv")):
        print("[ourafla] ì´ë¯¸ ë‹¤ìš´ë¡œë“œë¨, ê±´ë„ˆëœ€")
        return

    print("[ourafla] HuggingFaceì—ì„œ ë‹¤ìš´ë¡œë“œ ì¤‘...")
    ds = load_dataset("ourafla/Mental-Health_Text-Classification_Dataset")
    out_dir.mkdir(parents=True, exist_ok=True)

    for split_name, split_ds in ds.items():
        path = out_dir / f"{split_name}.csv"
        split_ds.to_csv(str(path))
        print(f"  {split_name}: {len(split_ds)}í–‰ â†’ {path}")

    print("[ourafla] ì™„ë£Œ\n")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. DepressionEmo (GitHub)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def download_depressionemo():
    """8ê°€ì§€ ìš°ìš¸ ê°ì • ë©€í‹°ë ˆì´ë¸” ë°ì´í„°ì…‹ (GitHub)"""
    out_dir = DATA_DIR / "depressionemo"
    if out_dir.exists() and any(out_dir.glob("*.json")):
        print("[DepressionEmo] ì´ë¯¸ ë‹¤ìš´ë¡œë“œë¨, ê±´ë„ˆëœ€")
        return

    print("[DepressionEmo] GitHubì—ì„œ ë‹¤ìš´ë¡œë“œ ì¤‘...")
    out_dir.mkdir(parents=True, exist_ok=True)

    base_url = "https://raw.githubusercontent.com/abuBakarSiddiqurRahman/DepressionEmo/main"
    files = ["train.json", "val.json", "test.json"]

    for fname in files:
        url = f"{base_url}/{fname}"
        dest = out_dir / fname
        try:
            urllib.request.urlretrieve(url, str(dest))
            # í–‰ ìˆ˜ í™•ì¸
            with open(dest, "r", encoding="utf-8") as f:
                data = json.load(f)
            print(f"  {fname}: {len(data)}í–‰ â†’ {dest}")
        except Exception as e:
            print(f"  âš ï¸ {fname} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            # ëŒ€ì²´ ê²½ë¡œ ì‹œë„ (Dataset/ í•˜ìœ„)
            url2 = f"{base_url}/Dataset/{fname}"
            try:
                urllib.request.urlretrieve(url2, str(dest))
                with open(dest, "r", encoding="utf-8") as f:
                    data = json.load(f)
                print(f"  {fname}: {len(data)}í–‰ â†’ {dest} (Dataset/ ê²½ë¡œ)")
            except Exception as e2:
                print(f"  âŒ {fname} ë‹¤ìš´ë¡œë“œ ìµœì¢… ì‹¤íŒ¨: {e2}")

    print("[DepressionEmo] ì™„ë£Œ\n")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. C-SSRS Reddit SuicideWatch (Kaggle)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def download_cssrs():
    """
    C-SSRS 7ë‹¨ê³„ ë ˆì´ë¸” ë°ì´í„°.
    Kaggle ë°ì´í„°ëŠ” ìˆ˜ë™ ë‹¤ìš´ë¡œë“œê°€ í•„ìš”í•  ìˆ˜ ìˆìŒ.
    kaggle APIê°€ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ìë™ ë‹¤ìš´ë¡œë“œ ì‹œë„.
    """
    out_dir = DATA_DIR / "cssrs"
    if out_dir.exists() and any(out_dir.glob("*.csv")):
        print("[C-SSRS] ì´ë¯¸ ë‹¤ìš´ë¡œë“œë¨, ê±´ë„ˆëœ€")
        return

    print("[C-SSRS] Kaggleì—ì„œ ë‹¤ìš´ë¡œë“œ ì‹œë„...")
    out_dir.mkdir(parents=True, exist_ok=True)

    try:
        subprocess.run(
            [
                "kaggle", "datasets", "download",
                "-d", "av9ash/labelled-reddit-suicidewatch-posts-cssr-s",
                "-p", str(out_dir), "--unzip"
            ],
            check=True,
            capture_output=True,
            text=True,
        )
        print(f"  â†’ {out_dir} ì— ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
    except FileNotFoundError:
        print("  âš ï¸ kaggle CLIê°€ ì—†ìŠµë‹ˆë‹¤.")
        print("  ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ í•„ìš”:")
        print("  https://www.kaggle.com/datasets/av9ash/labelled-reddit-suicidewatch-posts-cssr-s")
        print(f"  ë‹¤ìš´ë¡œë“œ í›„ {out_dir} í´ë”ì— CSV íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”.")
    except subprocess.CalledProcessError as e:
        print(f"  âš ï¸ kaggle ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e.stderr}")
        print("  ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ í•„ìš”:")
        print("  https://www.kaggle.com/datasets/av9ash/labelled-reddit-suicidewatch-posts-cssr-s")
        print(f"  ë‹¤ìš´ë¡œë“œ í›„ {out_dir} í´ë”ì— CSV íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”.")

    print("[C-SSRS] ì™„ë£Œ\n")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. ê¸°ì´ˆ íƒìƒ‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def explore_datasets():
    """ë‹¤ìš´ë¡œë“œëœ ë°ì´í„°ì…‹ì˜ ê¸°ë³¸ í†µê³„ ì¶œë ¥"""
    print("=" * 60)
    print("ë°ì´í„°ì…‹ ê¸°ì´ˆ íƒìƒ‰")
    print("=" * 60)

    # ourafla
    ourafla_dir = DATA_DIR / "ourafla"
    for csv_path in sorted(ourafla_dir.glob("*.csv")):
        print(f"\nğŸ“ ourafla/{csv_path.name}")
        with open(csv_path, "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            rows = list(reader)
        print(f"  í–‰ ìˆ˜: {len(rows)}")
        if rows:
            print(f"  ì»¬ëŸ¼: {list(rows[0].keys())}")
            # ë ˆì´ë¸” ë¶„í¬
            labels = {}
            text_col = None
            for col in rows[0].keys():
                if "status" in col.lower() or "label" in col.lower():
                    for r in rows:
                        lbl = r.get(col, "unknown")
                        labels[lbl] = labels.get(lbl, 0) + 1
                if "text" in col.lower() and text_col is None:
                    text_col = col
            if labels:
                print(f"  ë ˆì´ë¸” ë¶„í¬: {labels}")
            # ìƒ˜í”Œ 3ê°œ
            if text_col:
                print(f"  ìƒ˜í”Œ ('{text_col}' ì»¬ëŸ¼):")
                for r in rows[:3]:
                    txt = r[text_col][:100] + ("..." if len(r[text_col]) > 100 else "")
                    lbl = r.get("status", r.get("label", "?"))
                    print(f"    [{lbl}] {txt}")

    # DepressionEmo
    demodir = DATA_DIR / "depressionemo"
    for json_path in sorted(demodir.glob("*.json")):
        print(f"\nğŸ“ depressionemo/{json_path.name}")
        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        print(f"  í–‰ ìˆ˜: {len(data)}")
        if data:
            first = data[0]
            print(f"  í‚¤: {list(first.keys())}")
            # ê°ì • ë¶„í¬
            emotion_counts = {}
            for item in data:
                for emo in item.get("emotions", []):
                    emotion_counts[emo] = emotion_counts.get(emo, 0) + 1
            if emotion_counts:
                sorted_emo = sorted(emotion_counts.items(), key=lambda x: -x[1])
                print(f"  ê°ì • ë¶„í¬: {dict(sorted_emo)}")
            # ìƒ˜í”Œ 2ê°œ
            print(f"  ìƒ˜í”Œ:")
            for item in data[:2]:
                txt = item.get("text", item.get("post", ""))[:100]
                emo = item.get("emotions", [])
                print(f"    {emo} â†’ {txt}...")

    # C-SSRS
    cssrs_dir = DATA_DIR / "cssrs"
    for csv_path in sorted(cssrs_dir.glob("*.csv")):
        print(f"\nğŸ“ cssrs/{csv_path.name}")
        with open(csv_path, "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            rows = list(reader)
        print(f"  í–‰ ìˆ˜: {len(rows)}")
        if rows:
            print(f"  ì»¬ëŸ¼: {list(rows[0].keys())}")
            # ë ˆë²¨ ë¶„í¬
            levels = {}
            for r in rows:
                for col in r.keys():
                    if "level" in col.lower() or "score" in col.lower() or "cssrs" in col.lower():
                        lbl = r[col]
                        levels[lbl] = levels.get(lbl, 0) + 1
                        break
            if levels:
                print(f"  ë ˆë²¨ ë¶„í¬: {dict(sorted(levels.items()))}")
            # ìƒ˜í”Œ 2ê°œ
            print(f"  ìƒ˜í”Œ:")
            for r in rows[:2]:
                txt_col = next((c for c in r.keys() if "text" in c.lower() or "post" in c.lower() or "title" in c.lower()), list(r.keys())[0])
                txt = r[txt_col][:100]
                print(f"    {txt}...")


if __name__ == "__main__":
    download_ourafla()
    download_depressionemo()
    download_cssrs()

    print("\n")
    explore_datasets()
