# 한국어 임베딩 모델 비교 결과

실험일: 2026-02-23

## 평가 방법

| 평가                  | 스크립트         | 데이터                          | 측정 대상           |
| --------------------- | ---------------- | ------------------------------- | ------------------- |
| **프로토타입 분류**   | `02_score.py`    | 내 데이터셋 70,593개 (talksets) | 카테고리 분류 능력  |
| **의미 유사도 (STS)** | `06_sts_eval.py` | KLUE-STS validation 519쌍       | 순수 의미 배치 능력 |

> **KLUE-STS 평가는 내 데이터셋 임베딩과 무관합니다.**
> 각 모델에 KLUE-STS 문장쌍을 직접 인코딩해서 코사인 유사도를 계산한 것입니다.

---

## 프로토타입 분류 (`02_score.py`, talksets 70,593개)

| 모델                   | Accuracy  | Macro F1  | Weighted F1 | Silhouette↑ |
| ---------------------- | --------- | --------- | ----------- | ----------- |
| `BAAI/bge-m3`          | 38.6%     | 0.247     | 0.440       | -0.022      |
| `dragonkue/BGE-m3-ko`  | **39.4%** | **0.253** | **0.447**   | **-0.022**  |
| `upskyy/bge-m3-korean` | 34.9%     | 0.222     | 0.403       | -0.032      |

- **Accuracy / F1**: 카테고리 평균벡터(프로토타입)로 예측 vs 실제 레이블 비교
- **Silhouette**: 임베딩 공간에서 같은 카테고리끼리 뭉쳤는지 (코사인 거리 기준, +1=완벽 분리)
- 전 모델 Silhouette 음수 → 혐오표현 카테고리 경계가 임베딩 공간에 반영 안 됨 → Fine-tuning 필요

---

## 의미 유사도 (`06_sts_eval.py`, KLUE-STS 519쌍)

| 모델                   | Spearman ρ↑ | Pearson r↑ | 낮음(0~1) | 중간(1~3) | 높음(3~5) |
| ---------------------- | ----------- | ---------- | --------- | --------- | --------- |
| `BAAI/bge-m3`          | 0.8773      | 0.8717     | 0.372     | 0.753     | 0.621     |
| `dragonkue/BGE-m3-ko`  | **0.8869**  | **0.8796** | 0.351     | 0.751     | **0.629** |
| `upskyy/bge-m3-korean` | 0.8782      | 0.8708     | **0.403** | 0.703     | 0.606     |

- **Spearman ρ**: 모델 코사인 유사도 vs 사람 정답(0~5점)의 순위 상관계수
- `dragonkue` 1위 → "의미 가까운 문장은 가깝게, 다른 문장은 멀게" 가장 정확
- 0.87~0.88은 **우수** 수준 (SOTA ≈ 0.90~0.92)

---

## 결론

| 목적                       | 추천 모델                                  |
| -------------------------- | ------------------------------------------ |
| 한국어 **의미 유사도**     | `dragonkue/BGE-m3-ko`                      |
| **혐오표현 카테고리 분류** | Fine-tuning 필수 (3개 모두 Silhouette < 0) |

> `dragonkue/BGE-m3-ko`를 베이스로 talksets 데이터로 contrastive fine-tuning하면
> Silhouette가 양수로 올라갈 것으로 예상됩니다.
